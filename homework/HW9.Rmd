---
title: "HW9_TestScores"
name: Jess Daninhirsch
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
```

## Did a New Reading Program Lead to Better Scores?

The superintendent recently claimed that a new reading program has improved third-grade reading scores across the school district.

Before the program, third-grade students in the district averaged 72.6 points on standardized reading tests with a standard deviation of 4.8 points.

After implementing the program for one semester, you collected scores from 12 randomly selected classrooms:
74, 76, 73, 75, 78, 77, 74, 79, 75, 76, 77, 75

As a journalist, you need to determine: **Is there statistical evidence that reading scores have actually improved?**

## Task 1: Organize your data and initial assessment

Before you can run this codeblock, you will need to fill in a value where it says REPLACE_ME. That value can be found in the introduction.

```{r}
# Known information about reading scores before the new program
prior_mean <- 72.6  # average score
prior_sd <- 4.8     # standard deviation

# Reading scores after implementing the new program (12 classrooms)
new_scores <- c(74, 76, 73, 75, 78, 77, 74, 79, 75, 76, 77, 75) # Replace with the actual scores

# Create a journalist-friendly dataset
score_data <- tibble(
  classroom = paste("Classroom", 1:12),
  reading_score = new_scores
)

# View the data
score_data
```

### Reflection Question 1:
Based on just looking at the score_data dataframe, have test scores improved? How can you tell?
If the original average is 72.6 points, it looks like each classroom has improved because theya re all higher than the original mean. However, these are only showing one score from each classroom, not the average of every score within that classroom. They very well could be outliers, but we don't know for sure since they were randomly selected.


## Task 2: Calculate key statistics

Like Task 1, you will need to replace values where it says REPLACE_ME before running any code.


```{r}
# Calculate statistics based on the new reading scores
new_stats <- score_data |> 
  summarise(
    mean = mean(reading_score),
    sd = sd(reading_score),
    n = n()
  )

new_stats
```

### Reflection Question 2:
Looking at the mean and standard deviation of the new scores compared to the previous statistics, what initial observations can you make? What questions might these statistics raise for your reporting?

The new mean is certainly higher than the original mean, and the standard deviation is lower than the original as well. But again, this is a very small sample size, so I would likely ask the people who gathered the data about their methodology and ensure that everything was done ethically, and I may also ask them to collect more data to get a better picture.



## Task 3: Create a column chart

As before, replace any values marked REPLACE_ME based the instructions.


```{r}
# STUDENT TASK: Choose an appropriate fill color for the bars
my_fill_color <- "royalblue" # Replace with a color name like "royalblue", "darkgreen", etc.

# Create a visualization comparing new scores to the previous average
score_data |> 
ggplot(aes(x = classroom, y = reading_score)) +
  geom_col(fill = my_fill_color, alpha = 0.8) +
  geom_hline(yintercept = prior_mean, color = "darkred", size = 1, linetype = "dashed") +
  annotate("text", x = 2, y = prior_mean - 1, 
           label = "Previous Average (72.6)", hjust = 0, fontface = "bold", color = "darkred") +
  labs(
    title = "Reading Scores After New Program Implementation",
    subtitle = "Horizontal line shows previous district average of 72.6 points",
    x = NULL,
    y = "Reading Test Score",
    caption = "Source: District Assessment Data"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(face = "bold", size = 14),
    plot.subtitle = element_text(size = 10),
    axis.text.x = element_text(angle = 45, hjust = 1)
  )
```

### Reflection Question 3:
Examine the chart you created, and suggest a better title based on the results of the data, not a description.

Reading scores after new program implementation in comparison to the previous average

## Task 4: Perform a hypothesis test

This is where we formally test the superintendent's claim that reading scores have improved. Fill in the REPLACE_ME values as needed, beginning with your hypotheses.

**Hypotheses:**
Null: The new reading program had no effect on following reading scores.
Alternative: The new reading program had an effect on following reading scores.

```{r}
# Set the significance level for your test
alpha_level <- 0.05 # Replace with the appropriate value

# Perform a one-sample t-test
# Since we want to know if scores improved (increased), we use a one-sided test (alternative = "greater")
t_test_result <- t.test(
  score_data$reading_score,
  mu = prior_mean,
  alternative = "greater"
)

# Display the results
t_test_result
```

### Reflection Question 4:
What does the p-value tell you, and what doesn't it tell you? How would you explain these results to a non-technical audience while maintaining accuracy?

The p-value in non-scientific notation is 0.00003435. This is quite low, meaning that the statistical significance is low. In non-technical terms, the data collected shows that the new scores are higher than the average of the old scores, but it is not overly significant because the scores were chosen at random and do not provide the best big picture of the entire population.


## Task 5: Interpreting the results for your news story

Let's gather all of the important stats we'll need in one place, so we can look at the prior average, the new scores and the results of the t.test, including the confidence interval. Replace any values where it says REPLACE_ME.


```{r}
# Get the p-value
p_value <- t_test_result$p.value

# Calculate the 95% confidence interval
ci <- t.test(score_data$reading_score)$conf.int

# Create a tibble to display the key statistics for your story
story_stats <- tibble(
  `Previous average` = prior_mean,
  `New average` = mean(75.75),
  `Improvement` = mean(new_scores) - prior_mean,
  `Percent change` = round(((mean(new_scores) - prior_mean) / prior_mean) * 100, 1),
  `p-value` = p_value,
  `Lower bound` = ci[1],
  `Upper bound` = ci[2],
  `Confidence level` = "95%"
)

# Display the key statistics
story_stats
```

## Conclusion

### Reflection Question 5:
Based on these statistics, what would be your headline and lead paragraph for this story? Is there evidence to support the superintendent's claim?

HEADLINE: Evidence shows that a new reading program has potentially increased students' reading scores.

LEDE: Students took standardized reading tests before and after the implementation of a new reading program. Before this program, scores averaged around 72.6 points, and after the program, scores saw an improvement of 3.15 points. The average of one score taken at random from 12 different classrooms showed to be an average of 75.75 points. 
I believe there is enough evidence to support the superintendent's claim because there is a 95% confidence level, but the methodology should be noted high up in the story so that readers don't automatically assume that the reading program led directly to higher scores. There are other nuanced factors at play.

### Reflection Question 6:
What metrics or outcomes beyond test scores might be important to track for assessing reading performance?

Observing the behavior of students after this reading program is implemented would be important, although that might be hard to quantify. Regardless, if teachers actually notice improvement in reading skills, that is likely the number one indicator that the program is working. But some things that can be quantified are how many words a student can read per minute in how many pages they can read in a set amount of time. As a test-hater myself, I am a firm believer that standardized tests do not provide the best look at actual abilities or intelligence. 
