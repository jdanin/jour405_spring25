# JOUR405: Statistics for Journalists
## Midterm Exam - Spring 2025

Name: Jess Daninhirsch

For this exam, you'll analyze several datasets using R and the statistical concepts we've covered in class. Load the tidyverse before beginning, then complete each task. Write your code in the provided blocks and answer the questions in complete sentences. Start by loading the tidyverse and any other libraries you think you might need.

```{r}
library(tidyverse)
library(janitor)
```


## Part 1: Restaurant Health Inspections (15 points)

You want to understand how restaurants in Montgomery County are performing on health inspections. The first dataset contains restaurant health inspection scores for restaurants in Montgomery County. The dataset includes the name of the establishment, the number of points for critical and non-critical areas, the total points, maximum points possible and the compliance score and grade. Load the data from: `https://raw.githubusercontent.com/dwillis/jour405/refs/heads/main/data/montco_inspections.csv` and complete these tasks:
```{r}
moco_restaurants <- read_csv("https://raw.githubusercontent.com/dwillis/jour405/refs/heads/main/data/montco_inspections.csv")
```


### Tasks:
1. Calculate the mean and standard deviation of compliance scores (5 points)
2. Create a histogram of the compliance scores with a vertical line showing the mean (5 points)
3. Write 2-3 sentences interpreting what the standard deviation and histogram tell us about the distribution of compliance scores. What would be newsworthy about this distribution? What's the story here? (5 points).

```{r}
moco_restaurants |> summarize(mean = mean(compliance_score), sd = sd(compliance_score))

```
```{r}
moco_restaurants |> 
  ggplot() +
  geom_histogram(aes(x = compliance_score), binwidth = 6) 
```
3) The histogram shows the distribution of compliance scores is skewed to the right, showing that more of the restaurants in the dataset tend to have higher compliance scores than those that do not. The mean tells us that the average score for these is around 96 (a high A), but there are not that many restaurants that have a score of exactly 96 according to the shape of the histogram (a larger binwidth shows that more clearly). The standard deviation shows how spread out the data is and how much variation there is, so in the case of this dataset a lot of restaurants have similar scores (especially those to the right of the mean), and a lot of them have a perfect score. But the standard deviation being 5 means that there is a relatively hefty amount of variance throughout the dataset. The story here could be about the fact that a lot of restaurants in Montgomery County are very good, and maybe interview the people who do the inspections to learn about what they see. This may not be too data-focused, but when I see this dataset, I think of the act of gathering the data via conducting the inspections. I would want to get a behind the scenes look at what a health inspector does because it could bring in a human interest element.


## Part 2: High School Athletics (25 points)

You are reporting a story about high school sports participation in Maryland and want to see if there are differences between boys and girls. The second dataset shows participation numbers in high school sports across Maryland counties in 2024, broken down by sex. Load the data from: `https://raw.githubusercontent.com/dwillis/jour405/refs/heads/main/data/md_hs_participation.csv` and complete these tasks:
```{r}
hs_athletics <- read_csv("https://raw.githubusercontent.com/dwillis/jour405/refs/heads/main/data/md_hs_participation.csv")
```


### Tasks:
1. Calculate the correlation between boys' and girls' participation (5 points)
2. Add two columns called total and girls_pct using mutate(), with the total adding together boys and girls and girls_pct being the percentage of the total represented by girls participants. (5 points)
3. Create a scatterplot showing this relationship, adding a line of best fit (5 points)
4. In 2-3 sentences, explain what the correlation coefficient and scatterplot reveal about equity in Maryland high school sports participation. How do you interpret the school districts that are below the line vs those that are above? Which school districts are most worth examining further, and why? (10 points)
1)
```{r}
hs_athletics |> summarize(correlation = cor(boys, girls, method="pearson"))
```
2)
```{r}
hs_a_total <- hs_athletics |> mutate(total = boys + girls)
hs_all <- hs_a_total |> mutate(girls_pct = girls/total)

```
3)
```{r}
hs_all |> 
  ggplot() +
  geom_point(aes(x=total, y=girls_pct)) +
  geom_smooth(aes(x=total, y=girls_pct), method="lm") 

```
4. In 2-3 sentences, explain what the correlation coefficient and scatterplot reveal about equity in Maryland high school sports participation. How do you interpret the school districts that are below the line vs those that are above? Which school districts are most worth examining further, and why? (10 points)
4) The correlation coefficient shows that there is a strong correlation between the number of boys and the number of girls who participate in sports at each high school in Maryland. The schools that are above the line are schools in which girls make up a larger percentage of sports participation than boys, and the schools below the line have a smaller percentage of girls in sports than boys. The schools that I would want to examine further are the outliers, such as the one school with over 70% (Baltimore County Public Schools) of those participating in sports are girls and the one in which only 35% (Somerset County Public Schools) of those participating are girls to learn why it is more popular at a large school like BCPS for girls to participate and why it is less popular for a small school like Somerset County for girls to participate. I would want to further examine this and also take into account the size of each school.

## Part 3: Public Transit Ridership (20 points)

You are investigating public transit ridership in the Washington, D.C. area and want to understand the patterns of daily bus and rail ridership. The third dataset contains daily bus and rail ridership totals from WMATA for the past year. Load the data from https://raw.githubusercontent.com/dwillis/jour405/refs/heads/main/data/wmata_daily.csv and do the following:
```{r}
DC_rides <- read_csv("https://raw.githubusercontent.com/dwillis/jour405/refs/heads/main/data/wmata_daily.csv")
```

### Tasks:
1. Calculate the average bus and rail ridership and standard deviation using summarize() (5 points)
2. Using the process you used in class, take a random sample daily ridership numbers and calculate the sample means and deviations for bus and rail. The number in the sample is up to you, but explain why you chose what you did. Compare this to the stats you generated in step 1. (5 points)
3. Using group_by() and summarize(), calculate the means for bus and rail ridership for each weekday. Describe the overall pattern of ridership for bus and rail - which days stand out and why? Are there differences between bus and rail in the standard deviation values? (10 points)

1)
```{r}
DC_rides |> summarize(mean = mean(bus), sd = sd(bus))
DC_rides |> summarize(mean = mean(rail), sd = sd(rail))
```
2)
```{r}
sample100 <- DC_rides |> 
  sample_n(100)

sample100 |> summarize(mean_bus = mean(bus), sd_bus = sd(bus))
sample100 |> summarize(mean_rail = mean(rail), sd_rail = sd(rail))
```
3) 3. Using group_by() and summarize(), calculate the means for bus and rail ridership for each weekday. Describe the overall pattern of ridership for bus and rail - which days stand out and why? Are there differences between bus and rail in the standard deviation values? (10 points)

```{r}
DC_rides_bus <- DC_rides |> 
  group_by(weekday) |> 
  summarize(mean_bus = mean(bus)) |> 
  arrange(desc(mean_bus))

DC_rides_rail <- DC_rides |> 
  group_by(weekday) |> 
  summarize(mean_rail = mean(rail)) |> 
  arrange(desc(mean_rail))
```

The pattern for ridership by weekday shows that the average ridership on Friday through Monday for busses and for rail are ranked in the same order: Friday, followed by Monday, Saturday, then lastly sunday. Those days are less popular because of the weekend; people tend to stay home. Tuesday, Wednesday, and Thursday are ranked differently between bus and rail, with Tuesday being the more popular day for rail travel and Thursday more popular for bus. The difference between the most popular days for each mode of transportation and Sunday for each is quite stark, as well. The standard deviation for rail is about 20000 higher than bus, meaning that the rail has more variance, likely because the rail tends to be more popular on workdays.

## Part 4: Maryland Car Theft Rates (20 points)

Your editor has assigned you a story about car thefts in Maryland and wants you to analyze the data to find out which counties have the highest rates. The fourth dataset contains car theft statistics for Maryland counties in 2023 and population. Load the data from: `https://raw.githubusercontent.com/dwillis/jour405/refs/heads/main/data/md_car_thefts.csv` and complete the following tasks:
```{r}
MD_car_thefts <- read_csv("https://raw.githubusercontent.com/dwillis/jour405/refs/heads/main/data/md_car_thefts.csv")
```

### Tasks:
1. Using mutate, add a column that calculates the rate of car thefts for each county for 2023 - you need to choose the per capita rate and remember that columns beginning with a number need to be enclosed in backticks (5 points)
2. Calculate the median car theft rate and the total number of car thefts statewide. Which counties have rates above the median, and what percentage of all car thefts occur in those counties? (5 points)
3. Write 2-3 sentences describing what these calculations reveal about the distribution of car thefts in Maryland. What's the lede of a story about your findings? (10 points)

1)
```{r}
MD_carthefts_2023rate <- MD_car_thefts |> mutate(`2023rate` = `2023`/population * 1000)
```

2)
```{r}
MD_carthefts_2023rate |> summarize(median_2023rate = median(`2023rate`))

MD_carthefts_total <- MD_carthefts_2023rate |> mutate(total = sum(`2023`))

MD_carthefts_pct <- MD_carthefts_total |> mutate(pct = `2023`/total * 100)
```
The total is 23,871 statewide. 

The counties with rates above the median: Anne Arundel (4.5% of total), Baltimore City (29.9%), Baltimore County (10%), Cecil (0.62%), Charles (1.2%), Dorchester (0.39%), Howard (2.9%), Montgomery (9.7%), Prince George's (35%), St. Mary's (0.43%), Washington (1.1%), Wicomico (0.44%)

The counties with rates below the median: Allegany (0.14% of total), Calvert (0.2%), Caroline (0.12%), Carroll (0.29%), Frederick (0.73%), Garrett (0.03%), Harford (0.8), Kent (0.04%), Queen Anne's (0.06%), Somerset (0.1%), St. Mary's (0.43%), Talbot (0.1%), Worcester (0.16%)

3) Half of the counties listed are above the median, and half are below the median, meaning that there is an even distribution of car theft rates throughout the state. There are a few notable counties that have high percentages of the total, such as Baltimore City and Prince George's county. Here would be my lede:

Baltimore City and Prince George's County led the pack for car thefts in 2023 in Maryland. Most other counties in the state, though only account for small portions of the total number of car thefts in the state for 2023.

## Part 5: Data Analysis Scenario (20 points)

You receive a tip that local emergency response times have gotten significantly worse over the past year. You obtain monthly data on response times for police, fire and ambulance calls.

Write 3-4 sentences (no code!) explaining:
1. What statistical measures would you calculate to verify this claim? (10 points)
    I would likely find the averages for each month's response times and calculate the percent change to see how much they change month to month.
2. What visualizations would help readers understand the trends? (5 points)
    I think making a scatterplot would help show how the average response times for each month have changed.
3. What additional context or data would you need to make this a complete story? (5 points)
    I would want to know whether or not there are factors that affect response times, such as lack of resources/funding, and data about the number of emergency calls each month because if there are significantly less for one month, there would likely be lower response times for that month (so maybe I could find the correlation, too).


### Submission Instructions
- Save your work frequently
- Make sure all code blocks run without errors
- Provide clear explanations for your analytical choices
- Before submitting, clear your environment and run the entire notebook

Good luck!
